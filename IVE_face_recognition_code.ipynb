{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f234c7",
   "metadata": {},
   "source": [
    "# IVE face recognition project\n",
    "\n",
    "In this project...\n",
    "\n",
    "## STEP 1: Load the images and process data\n",
    "\n",
    "### 1.1 Retrieve the paths of the imagenes from the SQLite DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b352c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query:  ('C:\\\\Users\\\\lonel\\\\OneDrive\\\\Escritorio\\\\IVE face recognition\\\\Leeseo\\\\Le13.jpg', 'Leeseo')\n",
      "['Gaeul', 'Leeseo', 'Liz', 'Rei', 'Wonyoung', 'Yujin']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "## Connect Python with the created DB\n",
    "\n",
    "conn = sqlite3.connect('images.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "## Retrieve the paths and labels\n",
    "\n",
    "cursor.execute('SELECT file_path, label FROM images')\n",
    "data = cursor.fetchall() # This part creates a List of tuples that contains (file_path, label)\n",
    "\n",
    "cursor.execute(\"SELECT DISTINCT label FROM images\")\n",
    "unique_labels = [row[0] for row in cursor.fetchall()]\n",
    "print(unique_labels)\n",
    "print('vs')\n",
    "print('Original query random index: ', data[45]) # There are different members in the dataset, the insertion worked properly\n",
    "\n",
    "conn.close()\n",
    "\n",
    "## Make separate lists\n",
    "\n",
    "images_paths, labels = zip(*data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115b843",
   "metadata": {},
   "source": [
    "### 1.2 Load images using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "489d561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "## Comprove if the filepaths are correct:\n",
    "\n",
    "img = cv2.imread(images_paths[0]) # Load the first image\n",
    "cv2.imshow('First image:', img) # Display the first image\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() # All correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f5df28",
   "metadata": {},
   "source": [
    "### 1.3 Resizing & Normalization\n",
    "\n",
    "The machine learning model will need that all the images are the same size so we are going to preprocess the images in the next code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f980769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Define the size\n",
    "\n",
    "img_size = (224, 224)\n",
    "\n",
    "## Preprocess the images\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path) # Load images\n",
    "    img = cv2.resize(img, img_size) # Resize tthe images\n",
    "    img = img.astype('float32') / 225 # Normalize pixel values; pixel values scaled to [0,1] for better training performance\n",
    "\n",
    "    return img\n",
    "\n",
    "## Apply to all the images\n",
    "\n",
    "processed_images = np.array([preprocess_image(path) for path in images_paths])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52459d5",
   "metadata": {},
   "source": [
    "### 1.4 Encode labels for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483b6a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels:  ('Gaeul', 'Gaeul', 'Gaeul', 'Gaeul', 'Gaeul', 'Gaeul')\n",
      "Encoded labels:  [0 0 0 0 0 0]\n",
      "Another index of the labes:  Liz\n",
      "Another index of the encoded labes:  2\n",
      "Labels unique values:  ['Gaeul' 'Leeseo' 'Liz' 'Rei' 'Wonyoung' 'Yujin']\n",
      "Encoded labels unique values:  [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## Convert text labels to numbers\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)\n",
    "\n",
    "## See the result\n",
    "\n",
    "print('Original labels: ', labels[:6]) # It worked properly\n",
    "print('Encoded labels: ', encoded_labels[:6])\n",
    "\n",
    "print('Another index of the labes: ', labels[80])\n",
    "print('Another index of the encoded labes: ', encoded_labels[80])\n",
    "\n",
    "## Assure that all the members were correctly encoded\n",
    "\n",
    "print('Labels unique values: ', np.unique(labels))\n",
    "print('Encoded labels unique values: ', np.unique(encoded_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de709e",
   "metadata": {},
   "source": [
    "## 2. Extract Features Using PCA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
